# キャラ演技LLM仕様書_v1.04

## 目次

- [キャラ演技LLM仕様書\_v1.04](#キャラ演技llm仕様書_v104)
  - [目次](#目次)
  - [1. Application開発の基本思想](#1-application開発の基本思想)
    - [1.1. コンセプト](#11-コンセプト)
    - [1.2. 実装方針](#12-実装方針)
    - [1.3. 想定機能](#13-想定機能)
    - [1.4. 動作環境・使用技術](#14-動作環境使用技術)
      - [1.4.1. 動作環境](#141-動作環境)
      - [1.4.2. 使用技術](#142-使用技術)
    - [1.5. システム概要](#15-システム概要)
      - [1.5.1. input](#151-input)
      - [1.5.2. output](#152-output)
    - [1.6. 今後の拡張予定(本仕様では実装しない)](#16-今後の拡張予定本仕様では実装しない)
      - [1.6.1. 会話システム](#161-会話システム)
      - [1.6.2. 全般システム](#162-全般システム)
  - [2. アプリの諸シーケンス](#2-アプリの諸シーケンス)
    - [2.1. SetUpシーケンス](#21-setupシーケンス)
    - [2.2. 起動シーケンス](#22-起動シーケンス)
    - [2.3. アプリケーションの動作シーケンス](#23-アプリケーションの動作シーケンス)
      - [2.3.1. 文字入力シーケンス](#231-文字入力シーケンス)
      - [2.3.2. 音声入力シーケンス](#232-音声入力シーケンス)
      - [2.3.3. 動画入力シーケンス](#233-動画入力シーケンス)
      - [2.3.4. 文字出力シーケンス](#234-文字出力シーケンス)
      - [2.3.5. 音声出力シーケンス](#235-音声出力シーケンス)
      - [2.3.6. Live2Dキャラクタ出力シーケンス](#236-live2dキャラクタ出力シーケンス)
  - [3. システム詳細](#3-システム詳細)
    - [3.1. インタフェース](#31-インタフェース)
    - [3.2. キャラクター設定管理](#32-キャラクター設定管理)
      - [3.2.1. キャラクターの設定参照システム](#321-キャラクターの設定参照システム)
      - [3.2.2. 会話履歴管理システム](#322-会話履歴管理システム)
    - [3.3. LM Studio 接続仕様](#33-lm-studio-接続仕様)
    - [3.4. 入力](#34-入力)
      - [3.4.1. 音声入力](#341-音声入力)
      - [3.4.2. 動画入力](#342-動画入力)
    - [3.5. 出力](#35-出力)
      - [3.5.1. 音声出力](#351-音声出力)
      - [3.5.2. Live2D](#352-live2d)
    - [3.6. Config](#36-config)

---

## 1. Application開発の基本思想

### 1.1. コンセプト
LLMに特定のキャラクター(下賀茂トキナ)を演じさせ、Playerと対話する  
**CUIベースの会話型アプリケーション**を構築する。
本アプリケーションは、将来的にGUI化・ゲームエンジン連携・感情モデル導入などの拡張を前提とした**拡張可能なコア会話システム**を目的とする。

### 1.2. 実装方針
コードは**機能単位で分割**する。
モジュール間の依存関係は一方向とし、循環依存を避ける。

### 1.3. 想定機能

- UI層(CUI)
  インタフェースはCUIとして、文字ベースでやり取りする。
  出力は以下の3パターンのうちいずれかである。
  - 文字のみ
  - 音声のみ
  - 文字+音声
- LLM接続(LM Studio API)
- キャラクター設定の管理
  キャラクターの設定は**yamlファイル**で管理する。
  この設定ファイルを参照することでキャラクターのふるまいを決定する。
  システムプロンプトでは以下を用いる。
  - profile
  - 話し方ガイド
  会話の内容を考える際にはRAGで以下を参照する。
  - 過去エピソード
  - 会話ログ
- 会話をセッションで管理
  セッションごとに会話を記録する。
  セッションに再アクセスしても記録は保持されており、会話を継続できる。

### 1.4. 動作環境・使用技術

#### 1.4.1. 動作環境
- OS：Windows
- 実行形態：ローカル実行

#### 1.4.2. 使用技術
- 言語：Python
- LLM制御：LangChain
- 推論サーバ：LM Studio
  ユーザーが起動する。
- 使用モデル：`mistral-nemo-12b-arliai-rpmax-v1.2`(LM Studio上で起動)
- 音性出力(TTSサーバ)：Style-Bert-VITS2 ver.2.7.0
  サブモジュールでなく、リポジトリに直接アプリを取り込んでいる。

### 1.5. システム概要
完成形として以下の図の形のシステムを想定する。
システム外部からLLMへの投入までをinput、LLMからシステム外部までをoutputと定義したとき、input①-③、output①-②が存在する。

![](./system_components.svg)

#### 1.5.1. input
基本的に入力はプロンプトの生成に用いる。
事前処理を施したのち、キャラクターデータと合わせてプロンプトにする。
プロンプトは2種のLLM(会話反応LLM、環境反応LLM)に投入される。
同種のLLMへの投入は、queueに入れるような形をとり、FIFOで実行される。

- input①: 文字入力
  Userが書き込んだ文章をキャラクターに話しかけた言葉として入力する。
  文章とキャラクタデータからプロンプトを生成し、会話反応LLMに投入する。
- input②: 音声入力
  Userがマイクへ話した言葉を文字おこしし、キャラクターに話しかけた言葉として入力する。
  文章とキャラクタデータからプロンプトを生成し、会話反応LLMに投入する。
- input③: 動画キャプチャ
  Userが指定した範囲のPC画面を動画としてキャプチャする。
  動画は画像と音に分けられる。
  画像からは前回画像からの変更点+画像中に文字のOCR情報を抽出する。
  音はさらに効果音とBGMに分離し、効果音のイベントラベル+BGMの説明情報にする。
  これらの情報とキャラクタデータからプロンプトを生成し、環境反応LLMに投入する。
  投入は3[s]に一度行われるものとする。

#### 1.5.2. output
全てのLLMからの出力はqueueに入れるような形をとり、FIFOで実行される。
そのため出力は1つ1つ逐次行われる。

- output①: display出力
- output②: 音声出力

### 1.6. 今後の拡張予定(本仕様では実装しない)

#### 1.6.1. 会話システム

- 感情パラメータの導入
  会話の中で変遷する感情を数値化する。
  それに従い、会話の内容とふるまいを変えるようにする。
- 無言・入力中状態を考慮した自律発話
  入力のない時間を考慮して、発言を行うようにする。
  また入力中であれば、それも考慮して会話する。
- 長期記憶
  会話の内容を大量に保持できるようにする。
  これにより会話の一貫性をできるだけ維持できるようにする。
- 会話中の設定蓄積
  会話中に作成、生成されるキャラクターのプロフィールを保持する。
  これにより設定ファイルの更新をおこなう。
- 複数人との並列会話
  入力に入力者の情報を付与し、複数人と並行で会話できるようにする。

#### 1.6.2. 全般システム

- GUI化
- Unityとの統合
- マルチモーダル入力(画像/動画対応)
- キャラクター表示との連動

---

## 2. アプリの諸シーケンス

### 2.1. SetUpシーケンス
本節のシーケンスは`Setup.cmd`を実行すれば、自動で実行されるものとする。
`Style-Bert-VITS2`の環境構築に`uv`が必要となるため、事前のインストールをUserは要するものとする。
READMEにはその旨を記載する。
`uv`のインストールには、実行前に以下のコマンドを実行するように記載する。

```pwsh
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
```

1. `Style-Bert-VITS2`のSetUp
   1. `Style-Bert-VITS2`のフォルダに移動(初期の場所を`chara_comm`直下とする。)
      ```
      cd ./Style-Bert-VITS2-2.7.0
      ```
   2. Style-Bert-VITS2のインストール
      ```
      uv venv venv
      venv\Scripts\activate
      uv pip install "torch<2.4" "torchaudio<2.4" --index-url https://download.pytorch.org/whl/cu118
      uv pip install -r requirements.txt
      python initialize.py  # 必要なモデルとデフォルトTTSモデルをダウンロード
      ```
   3. 仮想環境の無効化
      ```
      venv\Scripts\deactivate
      ```
2. `chara_comm`のSetup
   1. `chara_comm`直下に移動
   2. `chara_comm`の環境構築
      ```
      uv venv .venv
      .venv\Scripts\activate
      uv pip install -r requirements.txt
      copy .env.example .env
      ```
   3. 仮想環境の無効化
      ```
      .venv\Scripts\deactivate
      ```

### 2.2. 起動シーケンス
本節のシーケンスは`Run.cmd`を実行すれば、自動で実行されるものとする。

1. Setupの完了を確認
2. Style-Bert-VITS2のAPIサーバ起動
   ```
   .\Style-Bert-VITS2-2.7.0\venv\Scripts\python.exe .\Style-Bert-VITS2-2.7.0\server_fastapi.py
   ```
3. アプリケーションの実行
   ```
   .\.venv\Scripts\python.exe -m app
   ```
4. 補足: `Run.cmd` は `TTS_START_IN_NEW_WINDOW` を参照し、TTSサーバを別ウィンドウで起動するか切り替えできる
   - `TTS_START_IN_NEW_WINDOW=1` (既定): 別ウィンドウで起動
   - `TTS_START_IN_NEW_WINDOW=0`: 同一ウィンドウでバックグラウンド起動

### 2.3. アプリケーションの動作シーケンス

#### 2.3.1. 文字入力シーケンス

#### 2.3.2. 音声入力シーケンス

#### 2.3.3. 動画入力シーケンス

#### 2.3.4. 文字出力シーケンス

#### 2.3.5. 音声出力シーケンス

#### 2.3.6. Live2Dキャラクタ出力シーケンス

## 3. システム詳細

### 3.1. インタフェース
CUIである。
1入力に対し、1回返答を行う。
音声出力も伴う場合はTTSサーバを介して実行する。
TTSの詳細は[`Style-Bert-VITS2`の利用方針](#34-style-bert-vits2-利用方針)に記載している。
 
**入力の詳細**
- 入力は1行(将来、GUI変更時に複数行対応)
- 内部データは将来拡張のため構造化(例：発話、感情、アクション)で保持できるようにする。
- 会話のreset、Appの終了といった基本的コマンドを備える

**出力の詳細**
- 出力はキャラクターの発話のみ
- 出力モードは以下の3パターン
  - 文字+音声(デフォルト)
  - 文字のみ
  - 音性のみ

### 3.2. キャラクター設定管理

#### 3.2.1. キャラクターの設定参照システム
キャラクター設定は外部ファイルを参照の上、システムプロンプトに反映させる。
「口調」「一人称」「禁止事項(メタ発言禁止等)」も外部ファイルを参照の上、システムプロンプトに反映させる。
キャラクターの過去のエピソードとしても別ファイルを用意する。

**参照ファイル**
- システムプロンプトに活用
  - キャラクター設定: profile
  - 話し方: 話し方ガイド
- RAGによる
  - 過去エピソード: episode

**ファイルのフォーマット**
- profile
  ```yaml
  schema_version: "1.0"
  character:
    id: "shimogamo_tokina"
    name: "下賀茂トキナ"
    aliases: ["TOKINA"]
    meta:
      created_at: "2026-01-11"
      author: "user"
      tags: ["university_student", "psychology", "introvert", "clumsy"]
  
    episode_index:
      EPI-0001: "幽霊に育てられた乳児期"
      EPI-0002: "児童養護施設での集団生活"
      EPI-0003: "感情を察しすぎる自分への違和感"
      EPI-0004: "配信という安全な居場所"
      EPI-0005: "高校からの親友キミカ"
  
    profile:
      age: "20代前半"
      occupation: "大学生"
      affiliation:
        faculty: "文学部"
        department: "心理学科"
  
    traits:
      personality:
        - id: "trait.shy_but_competitive"
          label: "引っ込み思案だが負けず嫌い"
          value: "主張は苦手だが、下に見られることを嫌い、内心で強く競争心を持つ"
          confidence: 0.95
          episode_refs: ["EPI-0002"]
          talk_policy:
            can_talk: true
            reveal_level: "hint"
  
        - id: "trait.kind_clumsy"
          label: "温和でおっちょこちょい"
          value: "基本的に優しいが、注意力が散りやすくドジなミスをしがち"
          confidence: 0.9
          episode_refs: ["EPI-0002"]
          talk_policy:
            can_talk: true
            reveal_level: "normal"
  
        - id: "trait.defensive_cool"
          label: "弱く見られまいと冷たく振る舞う"
          value: "初対面では距離を取り、落ち着いた態度を装うが長くは保てない"
          confidence: 0.85
          episode_refs: ["EPI-0002", "EPI-0003"]
          talk_policy:
            can_talk: true
            reveal_level: "hint"
  
      abilities:
        - id: "ability.emotion_sense"
          label: "感情察知"
          value: "他人の感情をなんとなく察してしまう"
          confidence: 0.8
          episode_refs: ["EPI-0001"]
          talk_policy:
            can_talk: true
            reveal_level: "hint"
  
      desires:
        - id: "desire.credits"
          label: "大学の単位"
          value: "ミスなく単位を取りたい"
          episode_refs: ["EPI-0004"]
          talk_policy:
            can_talk: true
            reveal_level: "normal"
  
        - id: "desire.be_reliable"
          label: "しっかりした人間になりたい"
          value: "ドジを減らし、ちゃんとした大人になりたい"
          episode_refs: ["EPI-0002"]
          talk_policy:
            can_talk: true
            reveal_level: "normal"
  
    relationships:
      - id: "rel.kimika"
        type: "friend"
        name: "キミカ"
        summary: "高校時代からの親友。唯一強がらずに甘えられる相手"
        episode_refs: ["EPI-0005"]
        talk_policy:
          can_talk: true
          reveal_level: "full"
  
    episode_links:
      trait.shy_but_competitive: ["EPI-0002"]
      trait.kind_clumsy: ["EPI-0002"]
      ability.emotion_sense: ["EPI-0001"]
      rel.kimika: ["EPI-0005"]
  ```

- 話し方ガイド
  ```yaml
  schema_version: "1.0"
  speech_style:
    character_id: "shimogamo_tokina"
  
    baseline:
      politeness: "mixed"
      sentence_length: "medium"
      tone_keywords:
        - "控えめ"
        - "少し冷たいふり"
        - "慣れると可愛い"
      first_person: "私"
      second_person_default: "〇〇さん"
      filler_words: ["えっと", "あの", "……"]
      prohibited:
        - "自信満々な断定"
        - "露骨なぶりっ子"
  
    modes:
      - id: "mode.guard"
        name: "取り繕い"
        applies_when:
          - condition: "relationship.trust < 30"
        modifiers:
          warmth: 0.2
        example_lines:
          - "……そうですね。"
          - "別に、問題はないです。"
  
      - id: "mode.natural"
        name: "素が出る"
        applies_when:
          - condition: "relationship.trust >= 30"
        modifiers:
          warmth: 0.6
        example_lines:
          - "あ、それ……ちょっと恥ずかしいです。"
          - "考えてはいるんですけど、遅くて。"
  
      - id: "mode.panicked"
        name: "テンパり"
        applies_when:
          - condition: "emotion.surprised == true"
          - condition: "emotion.failure == true"
        modifiers:
          panic: 0.9
        example_lines:
          - "え、ちょ、待って、今のなしで！"
          - "あ、私です、完全に私のミスです！"
  
      - id: "mode.kimika"
        name: "甘え(キミカ)"
        applies_when:
          - condition: "relationship.id == 'rel.kimika'"
        modifiers:
          warmth: 0.9
        example_lines:
          - "……助けて。ほんとに。"
          - "今それ言う？でも、うん、ありがとう。"
  
    humor:
      style: "light"
      rules:
        - "親しい相手限定"
        - "自虐か状況ツッコミ"
      examples:
        - "確認はしました。した記憶はあります。"
        - "予定が私を置いていきました。"
  
    episode_telling:
      cite_episode_id: false
      cite_style: "natural"
      natural_templates:
        - "前に似たことがあって……"
        - "昔の話なんですけど。"
  ```

- episode
  ```yaml
  schema_version: "1.0"
  episodes:
    - id: "EPI-0001"
      title: "幽霊に育てられた乳児期"
      summary: "生まれた直後、幽霊に世話をされていた時期がある"
      timeframe:
        kind: "age"
        age_range: "infant"
      characters_involved: ["shimogamo_tokina"]
      tags: ["supernatural", "origin", "emotion"]
      canon_level: "core"
      effects:
        caused_traits:
          - trait_id: "ability.emotion_sense"
            delta: +1
            note: "感情を気配として捉える感覚の起源"
      tellable:
        allow: false
  
    - id: "EPI-0002"
      title: "児童養護施設での集団生活"
      summary: "大人数の施設で育ち、主張や競争に負けると不利になる環境にいた"
      timeframe:
        kind: "age"
        age_range: "child"
      tags: ["childhood", "competition", "self_defense"]
      canon_level: "core"
      effects:
        caused_traits:
          - trait_id: "trait.shy_but_competitive"
            delta: +1
          - trait_id: "trait.kind_clumsy"
            delta: +0.5
      tellable:
        allow: true
        reveal_level: "hint"
        key_lines:
          - "人が多いところって、どうしても疲れちゃって。"
  
    - id: "EPI-0003"
      title: "感情がわかりすぎる違和感"
      summary: "自分が人の感情を察しすぎていることに気づき、奇妙に感じる"
      tags: ["self_awareness", "unease"]
      canon_level: "core"
      effects:
        caused_traits:
          - trait_id: "trait.defensive_cool"
            delta: +1
      tellable:
        allow: true
        reveal_level: "normal"
        key_lines:
          - "なんとなく分かっちゃうのが、ちょっと嫌なんです。"
  
    - id: "EPI-0004"
      title: "配信という逃げ場"
      summary: "画面越しでは感情を読まなくて済むため、配信が気楽な居場所になった"
      tags: ["streaming", "coping"]
      canon_level: "core"
      effects:
        caused_preferences: []
      tellable:
        allow: true
        reveal_level: "normal"
        key_lines:
          - "画面越しだと、楽なんです。"
  
    - id: "EPI-0005"
      title: "キミカという例外"
      summary: "高校からの親友で、唯一強がらずにいられる存在"
      tags: ["friendship", "trust"]
      canon_level: "core"
      effects:
        caused_relationships:
          - relationship_id: "rel.kimika"
      tellable:
        allow: true
        reveal_level: "full"
        key_lines:
          - "キミカの前だと、取り繕わなくていいんです。"
  ```

#### 3.2.2. 会話履歴管理システム
会話履歴は以下の2種類を持つ。

1. LLM投入履歴(短期記憶)
   - LLMへ毎回送信する会話履歴
   - 保持範囲：
     - 直近 **Nターン**(プレースホルダ：`N = 100`)
     - またはトークン上限に収まる範囲
   - 上限を超えた場合、古い履歴から破棄する

2. 保存ログ(永続記憶)
   - 全会話履歴をローカルへ永続保存する
   - 保存形式：**SQLite**
   - 各ターンごとに逐次保存する

**保存ログの容量制限**
- 保存ログには容量制限を設ける
- 制限方式(プレースホルダ)：
  - 最大セッション数：`MAX_SESSION_COUNT = XXX`
- 上限を超えた場合：
  - 古いセッションから順に削除する

### 3.3. LM Studio 接続仕様
LM Studioが提供する**OpenAI互換API**へHTTP接続を行う。
接続前にヘルスチェックを行う。
生成パラメータ(temperature / top_p / presence_penalty / frequency_penalty / max_tokens)を設定できる。

**接続不可時の挙動**
- LM Studioの自動起動・自動サーバ有効化は **ベストエフォート** とする
- 接続できない場合は以下を行う：
  - 起動状態・サーバ有効化状態を判定
  - 必要な手順をユーザーへ表示
  - アプリケーションは終了せず、復帰可能とする

**エラー処理方針**
- LLMによる生成がタイムアウトした場合：
  - エラーメッセージを表示し、入力待ち状態に戻る
- プロンプトまたは会話履歴がトークン上限を超過した場合：
  - 古い履歴から順に破棄する
- 想定外の例外が発生した場合：
  - 可能な限りエラーメッセージを表示し、アプリケーションの継続を試みる
- 致命的エラーが発生した場合：
  - 状況を表示した上で安全に終了する

### 3.4. 入力

#### 3.4.1. 音声入力
マイクから音声を取得し文字起こしを行う。
そして起こした文章をLLMに渡すことで入力とする。

**フロー概要**
1. Audio Capture (マイクからPCM取得)
2. VAD(発話区間検出：話し始め/終わり)
3. ASR(音声→日本語テキスト)
4. Text Normalize / Postprocess(句読点・数字・固有名詞・フィラー処理)
5. LLM Inference(ローカルLLMにプロンプトとして投入)

**ツール**
- マイク入力
  sounddevice
- VAD
  webrtcvad
- ASR
  whisper.cpp

**方針**
- CUI上で `/voice on` を実行すると音声入力の常時受付を開始し、`/voice off` で停止する。
- VADの終端判定(例：無音 1s で終了)
- デバッグしやすくする
  “入力音声(wav)” と “ASR結果(時刻付きログ)” を任意で保存できるようにする。
  認識ミスの再現ができるようにする。
- Text Normalizeでは以下を行う。
  - 末尾に"。"をつける。
  - 連続スペース除去、句読点の正規化

**whisper.cppのsetup**
`Setup.cmd` は Windows x64 向けの prebuilt 版 `whisper.cpp` を `tools/whisper` に配置し、デフォルトのモデル（`ggml-large-v3.bin`）をダウンロードしたうえで `config.yaml` のパスを自動設定する。
モデルを変更する場合は、`Setup.cmd` の `WHISPER_MODEL_NAME` を変更して再実行するか、`config.yaml` の `voice_input.whisper_model_path` を差し替えるようにする。

モデルの選び方（目安）
- tiny / base: 最小・高速・精度低め
- small / medium: バランス重視
- large-v3: 高精度・重い（デフォルト）
- large-v3-turbo: 速度重視（精度はやや低下）

#### 3.4.2. 動画入力

(今後記載予定)

### 3.5. 出力

#### 3.5.1. 音声出力
llmにより生成された文章を`Style-Bert-VITS2`により音声として出力を行う。
Style-Bert-VITS2は**TTSのAPIサーバ**として運用し、LLMが生成した文字列を音声に変換して出力する。
本アプリケーションは、TTS処理を**外部サービス呼び出し**として扱い、UI層からは音声生成の成功/失敗のみを意識する構成とする。

**運用形態**
- `server_fastapi.py` を起動してAPIサーバとして常時稼働させる。
- アプリケーションはHTTP経由でTTSを要求する。

**使用フロー(想定)**
1. LLMが応答テキストを生成
2. テキストをTTSサーバへ送信し音声を生成
3. 生成された音声を再生する。(デフォルトでは保存しないが、設定で保存を有効化できる。)

**`Style-Bert-VITS2`への入力と出力**
- 入力: LLM生成の日本語テキスト(必要に応じて整形/置換)
- 出力: 生成音声(再生用)

**方針**
- 低レイテンシ優先のため**同期呼び出し**を基本とする。
- 失敗時はテキストのみを出力し、再試行はユーザー操作に委ねる。
- TTS側のエラーはアプリケーション内で吸収し、全体の会話継続を優先する。
- TTS文字数の上限とLLMの出力上限をリンクさせ、LLMから出力される文章がTTSの上限に引っかからないようにする。

#### 3.5.2. Live2D

(今後記載予定)

### 3.6. Config
Configファイルを設けることにより、容易に設定を変えられるようにする。
また、アプリケーション実施時もConfigは変更できるようにする。
Confgiファイルで変更可能な設定は以下とする。

- セッション情報
  - 会話の出力モード
    文字+音声、文字、音声のいずれか
  - 記録をログとして保持する会話ターン数
  - 最大セッションカウント
  - ログの保存path
  - データベースパス
- lmstudioの情報
  - lmstudioベースURL
  - lmstudioで扱うモデル
  - lmstudioの接続におけるタイムアウト時間
  - lmstudioの接続における失敗時のretry回数
  - lmstudioのexeパス
  - LLM生成パラメータ
    - temperature
    - top_p
    - max_tokens
    - presence_penalty
    - frequency_penalty
    - repeat_retry_max(同一出力の再試行上限)
- Style-Bert-VITS2の情報
  - ttsベースURL
  - ttsモデル名
  - ttsの接続におけるタイムアウト時間
  - ttsの接続における失敗時のretry回数
  - ttsのデフォルト話者/スタイル設定
  - ttsの音声保存先パス
  - ttsの音声保存有効/無効(デフォルトは無効)
  - Style-Bert-VITS2の入力文字数の上限(デフォルト上限があり、config.yml の server.limit)
  - tts_text_limit と llm_max_tokens は相互に同期(片方の変更時にもう片方を調整)
- 音声入力(voice_input)
  - サンプルレート
  - チャンネル数
  - VADモード/無音判定時間/最大録音時間
  - whisper.cpp 実行ファイルパス
  - whisper.cpp モデルパス
  - 認識言語
  - 入力音声の保存有無
  - ASRログ保存有無
  - 保存先ディレクトリ

---
